[[_riot_file]]
= RIOT File
:connector: riot-file
:connector-title: RIOT File
:test-resources: ../../../../../connectors/riot-file/src/test/resources

{connector-title} lets you import and export local or remote files in many formats like CSV, JSON, and XML.

include::getting-started.adoc[leveloffset=+1]

== Importing

The `import` command reads data from files and writes it to Redis. The general usage is:

[subs="attributes,+quotes"]
....
[green]#riot-file# -h <host> -p <port> import [yellow]#FILE#... [REDIS COMMAND...]
....

To show the full usage, run:

[subs="attributes,+quotes"]
....
[green]#{connector}# import --help
....

=== Paths
Paths can include https://man7.org/linux/man-pages/man7/glob.7.html[wildcard patterns].

{connector-title} will try to determine the file type from its extension (e.g. `.csv` or `.json`), but you can specify it explicity using the `--filetype` option.

Gzipped files are supported and the extension before `.gz` is used (e.g. `myfile.json.gz` -> JSON type).

.Examples
* `/path/file.csv`
* `/path/file-*.csv`
* `/path/file.json`
* `\http://data.com/file.csv`
* `\http://data.com/file.json.gz`

TIP: Use `-` to read from standard input.

For AWS S3 buckets you can specify access and secret keys as well as the region for the bucket.

[subs="attributes,+quotes"]
....
[green]#{connector}# import s3://my-bucket/path/file.json --s3-region us-west-1 --s3-access xxxxxx --s3-secret xxxxxx
....

For Google Cloud Storage you can specify credentials and project id for the bucket:

[subs="attributes,+quotes"]
....
[green]#{connector}# import gs://my-bucket/path/file.json --gcs-key-file key.json --gcs-project-id my-gcp-project
....

=== Formats

{connector-title} supports a variety of file formats that can be imported into Redis:

* Delimited (CSV, TSV, PSV)
* Fixed-length aka fixed-width
* JSON
* XML

For flat file formats (delimited and fixed-length) you can use the `--header` option to automatically extract field names from the header. Otherwise specify the field names using the `--fields` option.

==== Delimited

The default delimiter character is comma (`,`). It can be changed with the `--delimiter` option.

Let's consider this CSV file:

.https://raw.githubusercontent.com/nickhould/craft-beers-dataset/master/data/processed/beers.csv[beers.csv]
[format="csv", options="header",grid="none",frame="none",cols="5%,5%,5%,5%,35%,35%,8%,7%"]
|===
,abv,ibu,id,name,style,brewery_id,ounces
0,0.05,,1436,Pub Beer,American Pale Lager,408,12.0
1,0.066,,2265,Devil's Cup,American Pale Ale (APA),177,12.0
2,0.071,,2264,Rise of the Phoenix,American IPA,177,12.0
|===

The following command imports that CSV file into Redis as hashes using `beer` as the key prefix and `id` as primary key. This creates hashes with keys `beer:1436`, `beer:2265`, ...

[source,bash]
----
include::{test-resources}/import-csv[]
----

This command imports a CSV file into a geo set named `airportgeo` with airport IDs as members:
[source,bash]
----
include::{test-resources}/import-geoadd[]
----

==== Fixed-Length

Fixed-length files can be imported by specifying the width of each field using the `--ranges` option.

[source,bash]
----
include::{test-resources}/import-fw[]
----

==== JSON

The expected format for JSON files is:

[source,json]
----
[
  {
    "...": "..."
  },
  {
    "...": "..."
  }
]
----

.JSON import example
[source,bash]
----
include::{test-resources}/import-json[]
----

JSON records are trees with potentially nested values that need to be flattened when the target is a Redis hash for example.

To that end, {connector-title} uses a field naming convention to flatten JSON objects and arrays:

.Nested object
[cols="45%m,10%,45%m",frame="none",grid="none"]
|=========================================================

|`{ "field": { "sub": "value" } }`| -> | `field.sub=value`

|=========================================================

.Array
[cols="45%m,10%,45%m",frame="none",grid="none"]
|=========================================================

|`{ "field": [1, 2, 3] }`| -> | `field[0]=1 field[1]=2 field[2]=3`

|=========================================================

==== XML

Here is a sample XML file that can be imported by {connector-title}:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<records>
    <trade>
        <isin>XYZ0001</isin>
        <quantity>5</quantity>
        <price>11.39</price>
        <customer>Customer1</customer>
    </trade>
    <trade>
        <isin>XYZ0002</isin>
        <quantity>2</quantity>
        <price>72.99</price>
        <customer>Customer2c</customer>
    </trade>
    <trade>
        <isin>XYZ0003</isin>
        <quantity>9</quantity>
        <price>99.99</price>
        <customer>Customer3</customer>
    </trade>
</records>
----

.XML Import Example
[source,bash]
----
include::{test-resources}/import-xml[]
----

==== Redis Dumps

{connector-title} can also import Redis data structure files in JSON or XML formats (see Export -> Redis to generate such files).

.Dump Import Example
[source,bash]
----
include::{test-resources}/import-dump[]
----

include::redis-commands.adoc[leveloffset=+2]

include::processing.adoc[leveloffset=+2]

== Exporting

The `export` command reads data from a Redis database and writes it to a JSON or XML file, potentially gzip-compressed. The general usage is:

[subs="attributes,+quotes"]
....
[green]#{connector}# -h <host> -p <port> export FILE
....

To show the full usage, run:

[subs="attributes,+quotes"]
....
[green]#{connector}# export --help
....

.Compressed JSON export example
[source,bash]
----
include::{test-resources}/export-json-gz[]
----

.XML export example
[source,bash]
----
include::{test-resources}/export-xml[]
----

.Exported file example
[source,json]
----
include::../resources/redis-dump.json[]
----
